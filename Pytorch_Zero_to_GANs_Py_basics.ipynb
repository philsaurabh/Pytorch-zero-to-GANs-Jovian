{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Zero to GANs-Py basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0Q6KW0qxUlnza7GX0RLgx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philsaurabh/Pytorch-zero-to-GANs-Jovian/blob/main/Pytorch_Zero_to_GANs_Py_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C4LbwL6tQNI"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O93hrQWfTE61"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw6WBKSzWUiF"
      },
      "source": [
        "# Tensor\n",
        "It is generalization term for vector, matrix or any n-dimensional array. It's an umbrella term."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehf1eAE3Wk35"
      },
      "source": [
        "### To create a floating point number in python (and pytorch) we use shorthand of that number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hYRJsuGWIQm",
        "outputId": "9e00fb44-2293-4b75-feb3-b851af9b5ec5"
      },
      "source": [
        "number1=torch.tensor(1.)\n",
        "number2=torch.tensor(2.1)\n",
        "print(number1)\n",
        "print(number2)\n",
        "print(number1.dtype)\n",
        "print(number1.shape)\n",
        "print(number2.dtype)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.)\n",
            "tensor(2.1000)\n",
            "torch.float32\n",
            "torch.Size([])\n",
            "torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9UWo3t-Xb30"
      },
      "source": [
        "### To create vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHnFbWwyXSX5",
        "outputId": "d3ab8961-4b8e-4507-c8af-8b73c021d205"
      },
      "source": [
        "vector1=torch.tensor([1,2,3.,4,5])\n",
        "print(vector1)\n",
        "print(vector1.shape)\n",
        "print(vector1.dtype)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3., 4., 5.])\n",
            "torch.Size([5])\n",
            "torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0h8w0GCXsni"
      },
      "source": [
        "All converted to floating point number"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b6-Q1GGYKXd"
      },
      "source": [
        "### To create matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APHBfoOAXrLS",
        "outputId": "893fd4e6-16f8-4aa3-e138-3e4651d4c75f"
      },
      "source": [
        "matrix1=torch.tensor([[1.,2],[2.,3],[4,5],[7,9]])\n",
        "print(matrix1)\n",
        "print(matrix1.shape)\n",
        "print(matrix1.dtype)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [2., 3.],\n",
            "        [4., 5.],\n",
            "        [7., 9.]])\n",
            "torch.Size([4, 2])\n",
            "torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49Ttv6yhYoc8"
      },
      "source": [
        "4 rows 2 columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wWPuFLiYsVP"
      },
      "source": [
        "### n-dimensional array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAiazJSdYmYT",
        "outputId": "3b3e32ad-6258-4ce7-8eee-78a53516ca89"
      },
      "source": [
        "arr1=torch.tensor([[[1,2],[2,3]],[[4,5],[7,9]]])\n",
        "arr2=torch.tensor([[[1.,2],[2,3]],[[4,5],[7,9]]])\n",
        "print(arr1)\n",
        "print(arr1.shape)\n",
        "print(arr1.dtype)\n",
        "print(arr2)\n",
        "print(arr2.shape)\n",
        "print(arr2.dtype)\n",
        "try:\n",
        "  arr3=torch.tensor([[[1.,2,.2],[2,3]],[[4,5],[7,9]]])\n",
        "  print(arr3.shape)\n",
        "  print(arr3.dtype)\n",
        "except ValueError as err:\n",
        "  print(err)\n",
        "  print(ValueError)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[1, 2],\n",
            "         [2, 3]],\n",
            "\n",
            "        [[4, 5],\n",
            "         [7, 9]]])\n",
            "torch.Size([2, 2, 2])\n",
            "torch.int64\n",
            "tensor([[[1., 2.],\n",
            "         [2., 3.]],\n",
            "\n",
            "        [[4., 5.],\n",
            "         [7., 9.]]])\n",
            "torch.Size([2, 2, 2])\n",
            "torch.float32\n",
            "expected sequence of length 3 at dim 2 (got 2)\n",
            "<class 'ValueError'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3B7IyhpbCK5"
      },
      "source": [
        "# Tensor operations and gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFYz9OXBbnJi"
      },
      "source": [
        "We can combine tensor with usual arithmetic operations available at python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DqEigexZ8hU"
      },
      "source": [
        "# Creating tensors.\n",
        "x= torch.tensor(2.)\n",
        "w= torch.tensor(3.,requires_grad=True)\n",
        "b= torch.tensor(4.,requires_grad=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0ZPFmM4cPbX"
      },
      "source": [
        "Arithmetic operation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dDeHKplcpm5"
      },
      "source": [
        "Combining Tensors to create new one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFfI2CGEcNRC",
        "outputId": "d7de6a09-6227-4762-8210-4c63d1c22b04"
      },
      "source": [
        "y=w*x+b\n",
        "y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtkMzfRLc3mI"
      },
      "source": [
        "In pytorch, we can automatically compute the derivative of y w.r.t. the tensors that have `require_grads` set to True(w,b). To compute derivatives, call \n",
        "`.backward `\n",
        "on result i.e. y. \n",
        "The results are stored in .grad property."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-P0mOSldjoa"
      },
      "source": [
        "# Computing Derivatives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozZ1slv9niI_"
      },
      "source": [
        "Gradients: With metrics\n",
        "\n",
        "Derivatives: With numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg5ZffugcnvM",
        "outputId": "9b9367f2-df0e-4933-df48-b000f2e6d2e0"
      },
      "source": [
        "y.backward()# works only on differentiable function, any complex function, uses calculus(not numerical methods generally)\n",
        "print('dy/dx',x.grad)\n",
        "print('dy/dw',w.grad)\n",
        "print('dy/db',b.grad)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dy/dx None\n",
            "dy/dw tensor(2.)\n",
            "dy/db tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VprmofViOVqN"
      },
      "source": [
        "### For matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22ELpUixL3EJ",
        "outputId": "70d51bbd-fe6e-43b7-ffee-d750db0079a3"
      },
      "source": [
        "# Creating tensors.\n",
        "x= torch.tensor([[1.,2],[2.,3],[4,5],[7,9]])\n",
        "w= torch.tensor([[1.,2],[2.,3],[4,5],[10,9]],requires_grad=True)\n",
        "b= torch.tensor([[10,2],[2.,3],[4,5],[7,9]],requires_grad=True)\n",
        "y=w*x+b\n",
        "print(y)\n",
        "external_grad = torch.tensor([[1.,1.],[1.,1.],[1.,1.],[1.,1.]])\n",
        "y.backward(gradient=external_grad)\n",
        "print('dy/dx',x.grad)\n",
        "print('dy/dw',w.grad)\n",
        "print('dy/db',b.grad)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[11.,  6.],\n",
            "        [ 6., 12.],\n",
            "        [20., 30.],\n",
            "        [77., 90.]], grad_fn=<AddBackward0>)\n",
            "dy/dx None\n",
            "dy/dw tensor([[1., 2.],\n",
            "        [2., 3.],\n",
            "        [4., 5.],\n",
            "        [7., 9.]])\n",
            "dy/db tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i_Ngsmen87b"
      },
      "source": [
        "# Interoperability with numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKaCygajoIMi"
      },
      "source": [
        "Numpy: \n",
        "\n",
        "*   Enables operations on large multidimensional arrays.\n",
        "*   Used for multiplication and scientific computings.\n",
        "*   Efficient because implemented in C++.\n",
        "*   Has large ecosystem of supporting libraries.\n",
        "*   Instead of reinventing the wheel(creating pre existing things), python interoperates really well numpy to levarage its existing ecosystem of tools and libraries.\n",
        "*   Interoperability is important because most of the most datasets are read and preprocessed as numpy arrays.\n",
        "*   Sometimes for deployment and web applications also, we have to convert to numpy arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEyQ7QIIqFNv"
      },
      "source": [
        "# Creating numpy array and converting it to pytorch tensor and vice versa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Capxa01123yA"
      },
      "source": [
        "## Some facts:\n",
        "* Arrays have arbitrary shapes whereas tensors have regular shape.\n",
        "* array and torch tensors exhibits same properties.\n",
        "* Pytorch is specifically desinged to work on GPUs.\n",
        "* To run any code on NVIDIA GPU, the code should be written in CUDA. It\n",
        "\n",
        " is a programming language like a flavour of C.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdHkIdanvMCs"
      },
      "source": [
        "Both have same datatypes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmqnWLzDdrxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db79803a-4cac-40c8-f208-e7964e4899eb"
      },
      "source": [
        "p=np.array([[1,2],[3.,4]])#numpy method\n",
        "q=torch.from_numpy(p)#torch method, thin wrpper from python to perform operation efficiently on GPU.\n",
        "r=q.numpy()#method of a tensor\n",
        "print(p)\n",
        "print(q)\n",
        "print(r)\n",
        "print(p.dtype)\n",
        "print(q.dtype)\n",
        "print(r.dtype)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 2.]\n",
            " [3. 4.]]\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]], dtype=torch.float64)\n",
            "[[1. 2.]\n",
            " [3. 4.]]\n",
            "float64\n",
            "torch.float64\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc1zmrFA8T1I"
      },
      "source": [
        "# Jovian Material"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "658ccRmP74HA"
      },
      "source": [
        "## Interoperability with Numpy\n",
        "\n",
        "[Numpy](http://www.numpy.org/) is a popular open-source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays and has a vast ecosystem of supporting libraries, including:\n",
        "\n",
        "* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n",
        "* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n",
        "* [OpenCV](https://opencv.org/) for image and video processing\n",
        "\n",
        "\n",
        "If you're interested in learning more about Numpy and other data science libraries in Python, check out this tutorial series: https://jovian.ai/aakashns/python-numerical-computing-with-numpy .\n",
        "\n",
        "Instead of reinventing the wheel, PyTorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhv1MshV7_bz"
      },
      "source": [
        "The interoperability between PyTorch and Numpy is essential because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n",
        "\n",
        "You might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n",
        "\n",
        "1. **Autograd**: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\n",
        "2. **GPU support**: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs.\n",
        "\n",
        "We'll leverage both these features of PyTorch extensively in this tutorial series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNbsuKta8OL0"
      },
      "source": [
        "## Summary and Further Reading\n",
        "\n",
        "Try out this assignment to learn more about tensor operations in PyTorch: https://jovian.ai/aakashns/01-tensor-operations\n",
        "\n",
        "\n",
        "This tutorial covers the following topics:\n",
        "\n",
        "* Introductions to PyTorch tensors\n",
        "* Tensor operations and gradients\n",
        "* Interoperability between PyTorch and Numpy\n",
        "\n",
        "\n",
        "You can learn more about PyTorch tensors here: https://pytorch.org/docs/stable/tensors.html. \n",
        "\n",
        "\n",
        "The material in this series is inspired by:\n",
        "\n",
        "* [PyTorch Tutorial for Deep Learning Researchers](https://github.com/yunjey/pytorch-tutorial) by Yunjey Choi \n",
        "* [FastAI development notebooks](https://github.com/fastai/fastai_docs/tree/master/dev_nb) by Jeremy Howard. \n",
        "\n",
        "With this, we complete our discussion of tensors and gradients in PyTorch, and we're ready to move on to the next topic: [Gradient Descent & Linear Regression](https://jovian.ai/aakashns/02-linear-regression)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgNLpHkI8SDK"
      },
      "source": [
        "## Questions for Review\n",
        "\n",
        "Try answering the following questions to test your understanding of the topics covered in this notebook:\n",
        "\n",
        "1. What is PyTorch?\n",
        "2. What is a Jupyter notebook?\n",
        "3. What is Google Colab?\n",
        "4. How do you install PyTorch?\n",
        "5. How do you import the `torch` module?\n",
        "6. What is a vector? Give an example.\n",
        "7. What is a matrix? Give an example.\n",
        "8. What is a tensor?\n",
        "9. How do you create a PyTorch tensor? Illustrate with examples.\n",
        "10. What is the difference between a tensor and a vector or a matrix?\n",
        "11. Is every tensor a matrix?\n",
        "12. Is every matrix a tensor?\n",
        "13. What does the `dtype` property of a tensor represent?\n",
        "14. Is it possible to create a tensor with elements of different data types?\n",
        "15. How do you inspect the number of dimensions of a tensor and the length along each dimension?\n",
        "16. Is it possible to create a tensor with the values `[[1, 2, 3], [4, 5]]`? Why or why not?\n",
        "17. How do you perform arithmetic operations on tensors? Illustrate with examples?\n",
        "18. What happens if you specify `requires_grad=True` while creating a tensor? Illustrate with an example.\n",
        "19. What is autograd in PyTorch? How is it useful?\n",
        "20. What happens when you invoke  the `backward` method of a tensor?\n",
        "21. How do you check the derivates of a result tensor w.r.t. the tensors used to compute its value?\n",
        "22. Give some examples of functions available in the `torch` module for creating tensors.\n",
        "23. Give some examples of functions available in the `torch` module for performing mathematical operations on tensors.\n",
        "24. Where can you find the list of tensor operations available in PyTorch?\n",
        "25. What is Numpy?\n",
        "26. How do you create a Numpy array?\n",
        "27. How do you create a PyTorch tensor using a Numpy array?\n",
        "28. How do you create a Numpy array using a PyTorch tensor?\n",
        "29. Why is interoperability between PyTorch and Numpy important?\n",
        "30. What is the purpose of a library like PyTorch if Numpy already provides data structures and utilities to with multi-dimensional numeric data?\n",
        "31. What is Jovian?\n",
        "32. How do you upload your notebooks to Jovian using `jovian.commit` ?"
      ]
    }
  ]
}